2020-04-05 17:49:21 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:179 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2020-04-05 17:49:21 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:148 - INFO ] Model summary:
ConvTasNet(
  (encoder_1d): Conv1D(1, 256, kernel_size=(20,), stride=(10,))
  (ln): ChannelWiseLayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (proj): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (repeats): Sequential(
    (0): Sequential(
      (0): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (1): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (2): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (3): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (4): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (5): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (6): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (7): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
    )
    (1): Sequential(
      (0): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (1): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (2): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (3): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (4): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (5): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (6): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (7): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
    )
    (2): Sequential(
      (0): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (1): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (2): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (3): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (4): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (5): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (6): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (7): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
    )
    (3): Sequential(
      (0): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (1): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (2): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (3): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (4): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (5): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (6): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
      (7): Conv1DBlock(
        (conv1x1): Conv1D(256, 512, kernel_size=(1,), stride=(1,))
        (prelu1): PReLU(num_parameters=1)
        (lnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dconv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)
        (prelu2): PReLU(num_parameters=1)
        (lnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (sconv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
    )
  )
  (mask): Conv1D(256, 768, kernel_size=(1,), stride=(1,))
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(20,), stride=(10,))
)
2020-04-05 17:49:21 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:150 - INFO ] Loading model to GPUs:(0,), #param: 8.82M
2020-04-05 17:49:21 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 17:49:33 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +34.19)...
2020-04-05 17:49:36 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 17:49:36 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:226 - INFO ] START FROM EPOCH 0, LOSS = 34.1597
2020-04-05 17:49:36 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 17:50:15 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +5.28)...
2020-04-05 17:50:54 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = +3.82)...
2020-04-05 17:51:33 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = +3.80)...
2020-04-05 17:52:12 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = +3.67)...
2020-04-05 17:52:51 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = +3.48)...
2020-04-05 17:52:52 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 17:53:04 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +3.69)...
2020-04-05 17:53:10 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 17:53:12 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  1: train = +4.0101(3.26m/1001) | dev = +3.7660(0.31m/250) 
2020-04-05 17:53:13 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 17:53:52 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +3.34)...
2020-04-05 17:54:32 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = +3.34)...
2020-04-05 17:55:11 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = +3.31)...
2020-04-05 17:55:50 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = +3.20)...
2020-04-05 17:56:30 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = +3.21)...
2020-04-05 17:56:30 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 17:56:41 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +3.35)...
2020-04-05 17:56:44 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 17:56:44 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  2: train = +3.2830(3.28m/1001) | dev = +3.4119(0.23m/250) 
2020-04-05 17:56:44 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 17:57:24 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +3.12)...
2020-04-05 17:58:03 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = +3.25)...
2020-04-05 17:58:43 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = +2.99)...
2020-04-05 17:59:23 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = +2.95)...
2020-04-05 18:00:02 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = +2.73)...
2020-04-05 18:00:02 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:00:13 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +2.89)...
2020-04-05 18:00:16 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:00:17 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  3: train = +3.0087(3.31m/1001) | dev = +2.9807(0.23m/250) 
2020-04-05 18:00:17 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:00:57 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +2.58)...
2020-04-05 18:01:36 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = +2.90)...
2020-04-05 18:02:16 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = +2.93)...
2020-04-05 18:02:56 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = +2.56)...
2020-04-05 18:03:36 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = +2.40)...
2020-04-05 18:03:36 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:03:47 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +2.73)...
2020-04-05 18:03:50 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:03:51 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  4: train = +2.6745(3.33m/1001) | dev = +2.7890(0.23m/250) 
2020-04-05 18:03:51 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:04:31 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +2.42)...
2020-04-05 18:05:12 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = +2.14)...
2020-04-05 18:05:51 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = +2.36)...
2020-04-05 18:06:31 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = +2.08)...
2020-04-05 18:07:11 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = +1.99)...
2020-04-05 18:07:11 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:07:22 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +2.27)...
2020-04-05 18:07:24 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:07:25 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  5: train = +2.1961(3.34m/1001) | dev = +2.2851(0.22m/250) 
2020-04-05 18:07:25 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:08:05 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +1.68)...
2020-04-05 18:08:45 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = +1.87)...
2020-04-05 18:09:25 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = +1.93)...
2020-04-05 18:10:04 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = +1.65)...
2020-04-05 18:10:44 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = +1.43)...
2020-04-05 18:10:44 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:10:55 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +1.94)...
2020-04-05 18:10:57 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:10:58 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  6: train = +1.7126(3.31m/1001) | dev = +1.9575(0.22m/250) 
2020-04-05 18:10:58 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:11:37 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +1.22)...
2020-04-05 18:12:17 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = +1.32)...
2020-04-05 18:12:56 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = +1.14)...
2020-04-05 18:13:36 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = +1.14)...
2020-04-05 18:14:16 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = +1.21)...
2020-04-05 18:14:16 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:14:27 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +1.55)...
2020-04-05 18:14:30 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:14:30 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  7: train = +1.2040(3.31m/1001) | dev = +1.5781(0.23m/250) 
2020-04-05 18:14:30 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:15:11 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +0.71)...
2020-04-05 18:15:51 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = +0.65)...
2020-04-05 18:16:31 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = +0.85)...
2020-04-05 18:17:10 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = +0.84)...
2020-04-05 18:17:50 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = +0.71)...
2020-04-05 18:17:50 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:18:01 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +1.37)...
2020-04-05 18:18:03 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:18:04 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  8: train = +0.7524(3.33m/1001) | dev = +1.3781(0.22m/250) 
2020-04-05 18:18:04 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:18:43 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +0.18)...
2020-04-05 18:19:23 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = +0.30)...
2020-04-05 18:20:02 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = +0.17)...
2020-04-05 18:20:42 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = +0.03)...
2020-04-05 18:21:21 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = +0.34)...
2020-04-05 18:21:21 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:21:32 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +0.81)...
2020-04-05 18:21:35 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:21:35 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  9: train = +0.2068(3.29m/1001) | dev = +0.7995(0.22m/250) 
2020-04-05 18:21:35 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:22:14 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -0.20)...
2020-04-05 18:22:54 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -0.48)...
2020-04-05 18:23:34 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -0.15)...
2020-04-05 18:24:13 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -0.26)...
2020-04-05 18:24:53 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -0.18)...
2020-04-05 18:24:53 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:25:04 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +0.71)...
2020-04-05 18:25:06 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:25:06 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 10: train = -0.2528(3.30m/1001) | dev = +0.7304(0.22m/250) 
2020-04-05 18:25:07 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:25:46 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -0.79)...
2020-04-05 18:26:26 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -0.86)...
2020-04-05 18:27:05 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -0.80)...
2020-04-05 18:27:45 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -0.67)...
2020-04-05 18:28:24 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -0.62)...
2020-04-05 18:28:24 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:28:35 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +0.60)...
2020-04-05 18:28:38 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:28:38 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 11: train = -0.7497(3.30m/1001) | dev = +0.6343(0.22m/250) 
2020-04-05 18:28:38 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:29:17 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -1.33)...
2020-04-05 18:29:57 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -1.26)...
2020-04-05 18:30:36 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -1.02)...
2020-04-05 18:31:16 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -1.01)...
2020-04-05 18:31:55 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -1.03)...
2020-04-05 18:31:55 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:32:06 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +0.36)...
2020-04-05 18:32:09 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:32:09 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 12: train = -1.1304(3.29m/1001) | dev = +0.4039(0.22m/250) 
2020-04-05 18:32:09 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:32:49 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -1.60)...
2020-04-05 18:33:28 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -1.37)...
2020-04-05 18:34:08 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -1.46)...
2020-04-05 18:34:47 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -1.59)...
2020-04-05 18:35:27 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -1.39)...
2020-04-05 18:35:27 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:35:38 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +0.47)...
2020-04-05 18:35:40 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:35:40 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 13: train = -1.4858(3.29m/1001) | dev = +0.4817(0.22m/250) | no impr, best = 0.4039
2020-04-05 18:35:40 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:36:20 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -2.06)...
2020-04-05 18:36:59 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -1.76)...
2020-04-05 18:37:39 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -1.87)...
2020-04-05 18:38:18 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -1.82)...
2020-04-05 18:38:58 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -1.76)...
2020-04-05 18:38:58 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:39:09 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +0.51)...
2020-04-05 18:39:11 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:39:11 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 14: train = -1.8501(3.29m/1001) | dev = +0.5180(0.22m/250) | no impr, best = 0.4039
2020-04-05 18:39:12 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:39:51 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -2.33)...
2020-04-05 18:40:31 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -2.27)...
2020-04-05 18:41:10 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -2.27)...
2020-04-05 18:41:49 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -2.09)...
2020-04-05 18:42:29 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -1.73)...
2020-04-05 18:42:29 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:42:40 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +0.27)...
2020-04-05 18:42:43 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:42:43 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 15: train = -2.1381(3.29m/1001) | dev = +0.2868(0.23m/250) 
2020-04-05 18:42:43 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:43:23 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -2.62)...
2020-04-05 18:44:02 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -2.55)...
2020-04-05 18:44:42 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -2.31)...
2020-04-05 18:45:21 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -2.14)...
2020-04-05 18:46:01 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -2.28)...
2020-04-05 18:46:01 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:46:12 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +0.06)...
2020-04-05 18:46:14 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:46:14 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 16: train = -2.3790(3.30m/1001) | dev = +0.0645(0.22m/250) 
2020-04-05 18:46:14 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:46:54 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -2.96)...
2020-04-05 18:47:33 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -2.90)...
2020-04-05 18:48:13 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -2.49)...
2020-04-05 18:48:52 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -2.43)...
2020-04-05 18:49:32 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -2.28)...
2020-04-05 18:49:32 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:49:43 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +0.30)...
2020-04-05 18:49:45 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:49:45 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 17: train = -2.6114(3.29m/1001) | dev = +0.3358(0.22m/250) | no impr, best = 0.0645
2020-04-05 18:49:45 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:50:25 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -3.12)...
2020-04-05 18:51:05 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -3.08)...
2020-04-05 18:51:44 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -2.96)...
2020-04-05 18:52:24 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -2.72)...
2020-04-05 18:53:03 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -2.53)...
2020-04-05 18:53:04 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:53:14 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +0.19)...
2020-04-05 18:53:17 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:53:17 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 18: train = -2.8808(3.30m/1001) | dev = +0.2059(0.22m/250) | no impr, best = 0.0645
2020-04-05 18:53:17 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:53:57 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -3.38)...
2020-04-05 18:54:36 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -3.30)...
2020-04-05 18:55:16 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -3.38)...
2020-04-05 18:55:55 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -2.95)...
2020-04-05 18:56:35 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -2.68)...
2020-04-05 18:56:35 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 18:56:46 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = +0.19)...
2020-04-05 18:56:48 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 18:56:48 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 19: train = -3.1385(3.30m/1001) | dev = +0.1818(0.22m/250) | no impr, best = 0.0645
2020-04-05 18:56:49 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 18:57:28 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -3.55)...
2020-04-05 18:58:08 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -3.64)...
2020-04-05 18:58:47 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -3.91)...
2020-04-05 18:59:27 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -3.92)...
2020-04-05 19:00:06 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -3.90)...
2020-04-05 19:00:06 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 19:00:17 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -0.48)...
2020-04-05 19:00:20 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 19:00:20 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 20: train = -3.7822(3.30m/1001) | dev = -0.4309(0.22m/250) 
2020-04-05 19:00:20 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 19:01:00 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -4.32)...
2020-04-05 19:01:39 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -4.34)...
2020-04-05 19:02:19 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -4.18)...
2020-04-05 19:02:58 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -4.30)...
2020-04-05 19:03:38 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -4.20)...
2020-04-05 19:03:38 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 19:03:49 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -0.43)...
2020-04-05 19:03:52 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 19:03:52 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 21: train = -4.2644(3.30m/1001) | dev = -0.4273(0.22m/250) | no impr, best = -0.4309
2020-04-05 19:03:52 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 19:04:31 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -4.76)...
2020-04-05 19:05:11 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -4.46)...
2020-04-05 19:05:50 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -4.66)...
2020-04-05 19:06:30 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -4.35)...
2020-04-05 19:07:09 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -4.51)...
2020-04-05 19:07:09 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 19:07:20 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -0.49)...
2020-04-05 19:07:23 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 19:07:23 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 22: train = -4.5504(3.29m/1001) | dev = -0.4515(0.22m/250) 
2020-04-05 19:07:23 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 19:08:03 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -4.93)...
2020-04-05 19:08:42 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -4.67)...
2020-04-05 19:09:22 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -4.84)...
2020-04-05 19:10:01 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -4.76)...
2020-04-05 19:10:41 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -4.63)...
2020-04-05 19:10:41 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 19:10:52 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -0.43)...
2020-04-05 19:10:54 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 19:10:54 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 23: train = -4.7659(3.29m/1001) | dev = -0.3823(0.22m/250) | no impr, best = -0.4515
2020-04-05 19:10:55 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 19:11:34 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -5.25)...
2020-04-05 19:12:14 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -5.03)...
2020-04-05 19:12:53 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -4.98)...
2020-04-05 19:13:33 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -4.78)...
2020-04-05 19:14:12 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -4.76)...
2020-04-05 19:14:13 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 19:14:23 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -0.47)...
2020-04-05 19:14:26 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 19:14:26 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 24: train = -4.9614(3.30m/1001) | dev = -0.4380(0.22m/250) | no impr, best = -0.4515
2020-04-05 19:14:26 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 19:15:06 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -5.36)...
2020-04-05 19:15:45 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -5.08)...
2020-04-05 19:16:25 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -5.23)...
2020-04-05 19:17:04 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -5.10)...
2020-04-05 19:17:44 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -5.05)...
2020-04-05 19:17:44 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 19:17:55 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -0.32)...
2020-04-05 19:17:58 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 19:17:58 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 25: train = -5.1643(3.30m/1001) | dev = -0.2929(0.22m/250) | no impr, best = -0.4515
2020-04-05 19:17:58 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 19:18:37 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -5.57)...
2020-04-05 19:19:17 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -5.52)...
2020-04-05 19:19:58 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -5.58)...
2020-04-05 19:20:37 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -5.50)...
2020-04-05 19:21:17 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -5.66)...
2020-04-05 19:21:17 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 19:21:28 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -0.50)...
2020-04-05 19:21:31 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 19:21:31 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=2.500e-04) - Epoch 26: train = -5.5696(3.32m/1001) | dev = -0.4677(0.22m/250) 
2020-04-05 19:21:31 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 19:22:11 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -5.85)...
2020-04-05 19:22:50 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -5.95)...
2020-04-05 19:23:30 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -5.90)...
2020-04-05 19:24:09 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -5.79)...
2020-04-05 19:24:49 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -5.76)...
2020-04-05 19:24:49 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 19:25:00 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -0.44)...
2020-04-05 19:25:02 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 19:25:02 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=2.500e-04) - Epoch 27: train = -5.8537(3.30m/1001) | dev = -0.4193(0.22m/250) | no impr, best = -0.4677
2020-04-05 19:25:03 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 19:25:42 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -6.07)...
2020-04-05 19:26:22 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -6.06)...
2020-04-05 19:27:01 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -6.14)...
2020-04-05 19:27:41 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -5.89)...
2020-04-05 19:28:20 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -6.07)...
2020-04-05 19:28:21 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 19:28:31 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -0.41)...
2020-04-05 19:28:34 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 19:28:34 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=2.500e-04) - Epoch 28: train = -6.0460(3.30m/1001) | dev = -0.3846(0.22m/250) | no impr, best = -0.4677
2020-04-05 19:28:34 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 19:29:14 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -6.20)...
2020-04-05 19:29:53 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -6.14)...
2020-04-05 19:30:33 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -6.26)...
2020-04-05 19:31:13 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -6.16)...
2020-04-05 19:31:52 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -6.26)...
2020-04-05 19:31:52 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 19:32:03 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -0.31)...
2020-04-05 19:32:06 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 19:32:06 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=2.500e-04) - Epoch 29: train = -6.2002(3.30m/1001) | dev = -0.3037(0.22m/250) | no impr, best = -0.4677
2020-04-05 19:32:06 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 19:32:45 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -6.53)...
2020-04-05 19:33:25 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -6.44)...
2020-04-05 19:34:04 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -6.35)...
2020-04-05 19:34:44 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -6.41)...
2020-04-05 19:35:23 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -6.55)...
2020-04-05 19:35:24 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 19:35:34 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -0.27)...
2020-04-05 19:35:37 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 19:35:37 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.250e-04) - Epoch 30: train = -6.4550(3.30m/1001) | dev = -0.2587(0.22m/250) | no impr, best = -0.4677
2020-04-05 19:35:37 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 19:36:17 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -6.75)...
2020-04-05 19:36:57 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -6.73)...
2020-04-05 19:37:37 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -6.53)...
2020-04-05 19:38:16 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -6.50)...
2020-04-05 19:38:56 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -6.56)...
2020-04-05 19:38:56 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 19:39:07 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -0.33)...
2020-04-05 19:39:09 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 19:39:09 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.250e-04) - Epoch 31: train = -6.6157(3.31m/1001) | dev = -0.3116(0.22m/250) | no impr, best = -0.4677
2020-04-05 19:39:09 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:186 - INFO ] Set train mode...
2020-04-05 19:39:49 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -6.78)...
2020-04-05 19:40:29 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 400 batches(loss = -6.59)...
2020-04-05 19:41:08 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 600 batches(loss = -6.74)...
2020-04-05 19:41:48 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 800 batches(loss = -6.79)...
2020-04-05 19:42:32 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 1000 batches(loss = -6.71)...
2020-04-05 19:42:32 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:205 - INFO ] Set eval mode...
2020-04-05 19:42:44 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:66 - INFO ] Processed 200 batches(loss = -0.28)...
2020-04-05 19:42:47 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:73 - INFO ] Loss on {:d} batches: ...
2020-04-05 19:42:48 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:252 - INFO ] Loss(time/N, lr=1.250e-04) - Epoch 32: train = -6.7243(3.37m/1001) | dev = -0.2762(0.26m/250) | no impr, best = -0.4677
2020-04-05 19:42:48 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:262 - INFO ] Stop training cause no impr for 6 epochs
2020-04-05 19:42:48 [/media/adam/ad_dev/dev/python/spksp/CSFP/SPK_SP_Master/nnet/libs/trainer.py:265 - INFO ] Training for 32/100 epoches done!
